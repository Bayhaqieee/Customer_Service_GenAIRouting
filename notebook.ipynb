{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e247051",
   "metadata": {},
   "source": [
    "# Customer Service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d0eff1",
   "metadata": {},
   "source": [
    "## Environment Config."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d7297b",
   "metadata": {},
   "source": [
    "### Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smart Loan Processing Foundation\n",
    "import asyncio\n",
    "import uuid\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Any, Optional, Union, Tuple\n",
    "from dataclasses import dataclass, field\n",
    "from enum import Enum\n",
    "import json\n",
    "import re\n",
    "import logging\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Google ADK Imports\n",
    "from google.adk.agents import Agent, SequentialAgent, ParallelAgent\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.models.lite_llm import LiteLlm\n",
    "from google.genai import types\n",
    "\n",
    "# LLM Imports\n",
    "# Import clients for both Azure and Ollama\n",
    "from openai import AzureOpenAI, APIConnectionError\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Verifying Loaded Environment Variables\n",
      "Azure Endpoint: your-azure-openai-endpoint\n",
      "Azure Key Loaded: True\n",
      "Ollama Host: http://localhost:11434\n",
      "--------------------------------------------\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Must provide either the `api_version` argument or the `OPENAI_API_VERSION` environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m--------------------------------------------\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Client Initialization\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m azure_client = \u001b[43mAzureOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# Configure the Ollama client\u001b[39;00m\n\u001b[32m     37\u001b[39m ollama.Client(host=os.environ.get(\u001b[33m'\u001b[39m\u001b[33mOLLAMA_HOST\u001b[39m\u001b[33m'\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\ML_Projects\\Customer_Service_GenAI\\venv\\Lib\\site-packages\\openai\\lib\\azure.py:207\u001b[39m, in \u001b[36mAzureOpenAI.__init__\u001b[39m\u001b[34m(self, api_version, azure_endpoint, azure_deployment, api_key, azure_ad_token, azure_ad_token_provider, organization, project, webhook_secret, websocket_base_url, base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[39m\n\u001b[32m    204\u001b[39m     api_version = os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mOPENAI_API_VERSION\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m api_version \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m207\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    208\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mMust provide either the `api_version` argument or the `OPENAI_API_VERSION` environment variable\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    209\u001b[39m     )\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m default_query \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    212\u001b[39m     default_query = {\u001b[33m\"\u001b[39m\u001b[33mapi-version\u001b[39m\u001b[33m\"\u001b[39m: api_version}\n",
      "\u001b[31mValueError\u001b[39m: Must provide either the `api_version` argument or the `OPENAI_API_VERSION` environment variable"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "# Load variables from your .env file\n",
    "load_dotenv()\n",
    "\n",
    "#  Configuration Block \n",
    "# We will read the variables directly from the environment here\n",
    "AZURE_ENDPOINT = os.environ.get(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_KEY = os.environ.get(\"AZURE_OPENAI_API_KEY\")\n",
    "AZURE_API_VERSION = os.environ.get(\"AZURE_OPENAI_API_VERSION\")\n",
    "AZURE_DEPLOYMENT = os.environ.get(\"AZURE_DEPLOYMENT_NAME\")\n",
    "\n",
    "OLLAMA_HOST = os.environ.get(\"OLLAMA_BASE_URL\")\n",
    "OLLAMA_MODEL = os.environ.get(\"OLLAMA_MODEL\")\n",
    "\n",
    "#  Client Initialization \n",
    "\n",
    "# MODIFIED: Reverted to explicit client initialization to be foolproof.\n",
    "# This directly passes the loaded variables to the client, solving the errors.\n",
    "azure_client = AzureOpenAI(\n",
    "    azure_endpoint=AZURE_ENDPOINT,\n",
    "    api_key=AZURE_KEY,\n",
    "    api_version=AZURE_API_VERSION,\n",
    ")\n",
    "\n",
    "# Set the model names for the agents to use later\n",
    "os.environ['AZURE_PRO_DEPLOYMENT'] = AZURE_DEPLOYMENT\n",
    "os.environ['OLLAMA_STANDARD_MODEL'] = OLLAMA_MODEL\n",
    "\n",
    "# Configure the Ollama client\n",
    "if OLLAMA_HOST:\n",
    "    ollama.Client(host=OLLAMA_HOST)\n",
    "\n",
    "print(\"Platform setup complete. Clients are configured.\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc68d34",
   "metadata": {},
   "source": [
    "## Agent Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425629cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specialized agent team created:\n",
      "Alex: technical specialist uses Azure (gpt-4o)\n",
      "Sarah: billing specialist uses Ollama (gemma3:latest)\n",
      "Mike: general specialist uses Ollama (gemma3:latest)\n",
      "Emma: escalation specialist uses Azure (gpt-4o)\n"
     ]
    }
   ],
   "source": [
    "class TicketType(Enum):\n",
    "    TECHNICAL = \"technical\"\n",
    "    BILLING = \"billing\"\n",
    "    GENERAL = \"general\"\n",
    "    ESCALATION = \"escalation\"\n",
    "\n",
    "@dataclass\n",
    "class CustomerTicket:\n",
    "    id: str\n",
    "    customer_name: str\n",
    "    issue: str\n",
    "    type: TicketType\n",
    "    priority: str\n",
    "    timestamp: str\n",
    "    status: str = \"open\"\n",
    "    assigned_agent: Optional[str] = None\n",
    "    resolution: Optional[str] = None\n",
    "    cost: float = 0.0\n",
    "\n",
    "class CustomerServiceAgent:\n",
    "    \"\"\"\n",
    "    An AI agent that can use either Azure OpenAI or a local Ollama instance.\n",
    "    \"\"\"\n",
    "    def __init__(self, name: str, specialization: TicketType, personality: str, model_preference: str, client: Optional[AzureOpenAI]):\n",
    "        self.name = name\n",
    "        self.specialization = specialization\n",
    "        self.personality = personality\n",
    "        self.model_preference = model_preference\n",
    "        self.azure_client = client\n",
    "        self.tickets_handled = []\n",
    "        self.total_cost = 0.0\n",
    "\n",
    "        if self.model_preference == \"pro\":\n",
    "            self.model_name = os.environ.get('AZURE_PRO_DEPLOYMENT')\n",
    "            self.cost_per_prompt_token = 0.01 / 1000\n",
    "            self.cost_per_completion_token = 0.03 / 1000\n",
    "        else: # Standard (Ollama)\n",
    "            self.model_name = os.environ.get('OLLAMA_STANDARD_MODEL')\n",
    "            self.cost_per_prompt_token = 0.0001 / 1000\n",
    "            self.cost_per_completion_token = 0.0002 / 1000\n",
    "\n",
    "    # MODIFIED: Corrected the return type hint from (str, int) to Tuple[str, int]\n",
    "    def handle_ticket(self, ticket: CustomerTicket) -> Tuple[str, int]:\n",
    "        \"\"\"\n",
    "        Handles a ticket by routing to the appropriate LLM service (Azure or Ollama).\n",
    "        Returns the resolution text and total tokens used.\n",
    "        \"\"\"\n",
    "        system_prompt = f\"You are {self.name}, a {self.specialization.value} support specialist. PERSONALITY: {self.personality}. Provide a helpful, professional, and concise response under 150 words.\"\n",
    "        user_prompt = f\"Customer: {ticket.customer_name}\\nIssue: {ticket.issue}\\nPriority: {ticket.priority}\"\n",
    "        messages = [{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": user_prompt}]\n",
    "\n",
    "        # MODIFIED: Improved error handling to be more specific\n",
    "        try:\n",
    "            if self.model_preference == \"pro\":\n",
    "                if not self.azure_client:\n",
    "                    raise ValueError(\"Azure client is not configured for Pro agent.\")\n",
    "                response = self.azure_client.chat.completions.create(model=self.model_name, messages=messages, max_tokens=200, temperature=0.7)\n",
    "                resolution = response.choices[0].message.content\n",
    "                prompt_tokens = response.usage.prompt_tokens\n",
    "                completion_tokens = response.usage.completion_tokens\n",
    "            else: # Ollama\n",
    "                response = ollama.chat(model=self.model_name, messages=messages)\n",
    "                resolution = response['message']['content']\n",
    "                prompt_tokens = response.get('prompt_eval_count', 0)\n",
    "                completion_tokens = response.get('eval_count', 0)\n",
    "\n",
    "            total_tokens = prompt_tokens + completion_tokens\n",
    "            ticket_cost = (prompt_tokens * self.cost_per_prompt_token) + (completion_tokens * self.cost_per_completion_token)\n",
    "            \n",
    "            # Update ticket and agent state\n",
    "            ticket.assigned_agent = self.name\n",
    "            ticket.resolution = resolution\n",
    "            ticket.status = \"resolved\"\n",
    "            ticket.cost = ticket_cost\n",
    "            self.tickets_handled.append(ticket.id)\n",
    "            self.total_cost += ticket_cost\n",
    "\n",
    "            return resolution, total_tokens\n",
    "\n",
    "        except APIConnectionError as e:\n",
    "            error_message = f\"Azure Connection Error: Could not connect to endpoint. Check your network and endpoint URL. Details: {e.__cause__}\"\n",
    "            return error_message, 0\n",
    "        except Exception as e:\n",
    "            if self.model_preference == 'standard':\n",
    "                error_message = f\"Ollama Error: Could not connect to Ollama at '{os.environ.get('OLLAMA_HOST')}'. Is the service running? Details: {str(e)}\"\n",
    "            else:\n",
    "                 error_message = f\"An unexpected error occurred: {str(e)}\"\n",
    "            return error_message, 0\n",
    "\n",
    "# Create the agent team with different client configurations\n",
    "agent_team = {\n",
    "    \"alex_tech\": CustomerServiceAgent(name=\"Alex\", specialization=TicketType.TECHNICAL, personality=\"Analytical and detail-oriented.\", model_preference=\"pro\", client=azure_client),\n",
    "    \"sarah_billing\": CustomerServiceAgent(name=\"Sarah\", specialization=TicketType.BILLING, personality=\"Empathetic and patient.\", model_preference=\"standard\", client=None),\n",
    "    \"mike_general\": CustomerServiceAgent(name=\"Mike\", specialization=TicketType.GENERAL, personality=\"Friendly and efficient.\", model_preference=\"standard\", client=None),\n",
    "    \"emma_escalation\": CustomerServiceAgent(name=\"Emma\", specialization=TicketType.ESCALATION, personality=\"Calm and authoritative.\", model_preference=\"pro\", client=azure_client)\n",
    "}\n",
    "print(\"Specialized agent team created:\")\n",
    "for _, agent in agent_team.items():\n",
    "    api_service = \"Azure\" if agent.model_preference == 'pro' else \"Ollama\"\n",
    "    print(f\"{agent.name}: {agent.specialization.value} specialist uses {api_service} ({agent.model_name})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed52eee6",
   "metadata": {},
   "source": [
    "## Intelligent Routing System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90b859f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intelligent Routing System is ready.\n"
     ]
    }
   ],
   "source": [
    "class IntelligentRouter:\n",
    "    def __init__(self, agent_team: Dict[str, CustomerServiceAgent]):\n",
    "        self.agent_team = agent_team\n",
    "        self.routing_history = []\n",
    "        self.classification_keywords = {\n",
    "            TicketType.TECHNICAL: ['bug', 'error', 'crash', 'login', 'password', 'setup', 'install', 'technical', 'not working'],\n",
    "            TicketType.BILLING: ['bill', 'charge', 'payment', 'refund', 'invoice', 'subscription', 'pricing', 'cost'],\n",
    "            TicketType.GENERAL: ['question', 'how to', 'information', 'help', 'support', 'general'],\n",
    "            TicketType.ESCALATION: ['manager', 'complaint', 'urgent', 'escalate', 'supervisor', 'legal', 'dispute']\n",
    "        }\n",
    "\n",
    "    def classify_ticket(self, issue_text: str, priority: str) -> TicketType:\n",
    "        issue_lower = issue_text.lower()\n",
    "        if priority == \"urgent\" or any(keyword in issue_lower for keyword in self.classification_keywords[TicketType.ESCALATION]):\n",
    "            return TicketType.ESCALATION\n",
    "        scores = {ttype: sum(1 for kw in kws if kw in issue_lower) for ttype, kws in self.classification_keywords.items() if ttype != TicketType.ESCALATION}\n",
    "        if max(scores.values()) > 0: return max(scores, key=scores.get)\n",
    "        return TicketType.GENERAL\n",
    "\n",
    "    def route_ticket(self, ticket: CustomerTicket) -> str:\n",
    "        suitable_agents = [(aid, agent) for aid, agent in self.agent_team.items() if agent.specialization == ticket.type]\n",
    "        if not suitable_agents: suitable_agents = [(aid, agent) for aid, agent in self.agent_team.items() if agent.specialization == TicketType.GENERAL]\n",
    "        selected_agent_id, _ = min(suitable_agents, key=lambda x: len(x[1].tickets_handled))\n",
    "        self.routing_history.append({'ticket_id': ticket.id, 'assigned_agent': selected_agent_id})\n",
    "        return selected_agent_id\n",
    "\n",
    "router = IntelligentRouter(agent_team)\n",
    "print(\"Intelligent Routing System is ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3236ddfd",
   "metadata": {},
   "source": [
    "## Customer Scenario w/ Rate Limiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b0a51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROCESSING CUSTOMER SCENARIOS (WITH RATE LIMITING)...\n",
      "Rate Limit: 20000 tokens/minute\n",
      "============================================================\n",
      "\n",
      "TICKET CS-2024-001:\n",
      "  Customer: Jennifer Martinez | Assigned to: Mike\n",
      "RESOLVED: Subject: Regarding Your Login Issue - Jennifer Martinez\n",
      "\n",
      "Hi Jennifer,\n",
      "\n",
      "Thanks for reaching out! I un...\n",
      "Cost: $0.000030 | Tokens used: 183\n",
      "\n",
      "One-minute window has reset.\n",
      "\n",
      "TICKET CS-2024-002:\n",
      "  Customer: David Chen | Assigned to: Sarah\n",
      "RESOLVED: Okay David, thank you for reaching out. I understand your frustration with being charged twice this ...\n",
      "Cost: $0.000032 | Tokens used: 195\n",
      "\n",
      "TICKET CS-2024-003:\n",
      "  Customer: Lisa Thompson | Assigned to: Mike\n",
      "RESOLVED: Subject: Setting Up Your First Project - Let's Get Started!\n",
      "\n",
      "Hi Lisa,\n",
      "\n",
      "Thanks for reaching out! Sett...\n",
      "Cost: $0.000036 | Tokens used: 214\n",
      "\n",
      "One-minute window has reset.\n",
      "\n",
      "TICKET CS-2024-004:\n",
      "  Customer: Robert Johnson | Assigned to: Emma\n",
      "FAILED: Azure Connection Error: Could not connect to endpoint. Check your network and endpoint URL. Details: Request URL is missing an 'http://' or 'https://' protocol.\n",
      "\n",
      "TICKET CS-2024-005:\n",
      "  Customer: Maria Garcia | Assigned to: Alex\n",
      "FAILED: Azure Connection Error: Could not connect to endpoint. Check your network and endpoint URL. Details: Request URL is missing an 'http://' or 'https://' protocol.\n"
     ]
    }
   ],
   "source": [
    "customer_scenarios = [\n",
    "    {\"customer_name\": \"Jennifer Martinez\", \"issue\": \"I'm having trouble logging into my account.\", \"priority\": \"medium\"},\n",
    "    {\"customer_name\": \"David Chen\", \"issue\": \"I was charged twice for my subscription this month.\", \"priority\": \"high\"},\n",
    "    {\"customer_name\": \"Lisa Thompson\", \"issue\": \"I want to know how to set up my first project.\", \"priority\": \"low\"},\n",
    "    {\"customer_name\": \"Robert Johnson\", \"issue\": \"I must speak to a manager about a complaint!\", \"priority\": \"urgent\"},\n",
    "    {\"customer_name\": \"Maria Garcia\", \"issue\": \"The mobile app keeps crashing when I upload files.\", \"priority\": \"high\"}\n",
    "]\n",
    "\n",
    "processed_tickets = []\n",
    "TOKEN_PER_MINUTE_LIMIT = 20000\n",
    "tokens_used_this_minute = 0\n",
    "window_start_time = time.time()\n",
    "\n",
    "print(\"\\nPROCESSING CUSTOMER SCENARIOS (WITH RATE LIMITING)...\")\n",
    "print(f\"Rate Limit: {TOKEN_PER_MINUTE_LIMIT} tokens/minute\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, scenario in enumerate(customer_scenarios, 1):\n",
    "    current_time = time.time()\n",
    "    if current_time - window_start_time > 60:\n",
    "        print(\"\\nOne-minute window has reset.\")\n",
    "        tokens_used_this_minute, window_start_time = 0, current_time\n",
    "    if tokens_used_this_minute >= TOKEN_PER_MINUTE_LIMIT:\n",
    "        wait_time = 60 - (current_time - window_start_time)\n",
    "        if wait_time > 0:\n",
    "            print(f\"\\nRate limit reached. Waiting for {wait_time:.1f} seconds...\")\n",
    "            time.sleep(wait_time)\n",
    "        tokens_used_this_minute, window_start_time = 0, time.time()\n",
    "\n",
    "    ticket_id = f\"CS-2024-{str(i).zfill(3)}\"\n",
    "    ticket_type = router.classify_ticket(scenario['issue'], scenario['priority'])\n",
    "    ticket = CustomerTicket(id=ticket_id, **scenario, type=ticket_type, timestamp=datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "    assigned_agent_id = router.route_ticket(ticket)\n",
    "    assigned_agent = agent_team[assigned_agent_id]\n",
    "    \n",
    "    print(f\"\\nTICKET {ticket_id}:\")\n",
    "    print(f\"  Customer: {ticket.customer_name} | Assigned to: {assigned_agent.name}\")\n",
    "    \n",
    "    resolution, tokens_used = assigned_agent.handle_ticket(ticket)\n",
    "    if tokens_used > 0:\n",
    "        tokens_used_this_minute += tokens_used\n",
    "        print(f\"RESOLVED: {resolution[:100]}...\")\n",
    "        print(f\"Cost: ${ticket.cost:.6f} | Tokens used: {tokens_used}\")\n",
    "    else:\n",
    "        print(f\"FAILED: {resolution}\")\n",
    "\n",
    "    processed_tickets.append(ticket)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5025bd",
   "metadata": {},
   "source": [
    "## Platform Analytics and Monitorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441dfa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomerServicePlatform:\n",
    "    def __init__(self, agent_team: Dict[str, CustomerServiceAgent], router: IntelligentRouter):\n",
    "        self.agent_team = agent_team\n",
    "        self.router = router\n",
    "\n",
    "    def export_platform_report(self) -> str:\n",
    "        agent_performance, total_cost = {}, 0.0\n",
    "        for agent in self.agent_team.values():\n",
    "            total_cost += agent.total_cost\n",
    "            agent_performance[agent.name] = {\n",
    "                'service': \"Azure\" if agent.model_preference == 'pro' else \"Ollama\",\n",
    "                'model': agent.model_name,\n",
    "                'tickets_handled': len(agent.tickets_handled),\n",
    "                'total_cost': agent.total_cost,\n",
    "                'avg_cost_per_ticket': agent.total_cost / max(len(agent.tickets_handled), 1)\n",
    "            }\n",
    "        \n",
    "        report = f\"\\n\\n{'=' * 60}\\nHYBRID CUSTOMER SERVICE PLATFORM REPORT\\n{'=' * 60}\\n\"\n",
    "        report += \"\\n👥 AGENT PERFORMANCE:\\n\"\n",
    "        for name, perf in agent_performance.items():\n",
    "            report += f\"\"\"\n",
    "  {name}:\n",
    "     • Service: {perf['service']}\n",
    "     • Model: {perf['model']}\n",
    "     • Tickets Handled: {perf['tickets_handled']}\n",
    "     • Total Cost: ${perf['total_cost']:.6f}\n",
    "     • Avg Cost/Ticket: ${perf['avg_cost_per_ticket']:.6f}\n",
    "\"\"\"\n",
    "        report += f\"\\nGRAND TOTAL COST: ${total_cost:.6f}\\n{'=' * 60}\"\n",
    "        return report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdd3ef1",
   "metadata": {},
   "source": [
    "## Create Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5a245a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "============================================================\n",
      "HYBRID CUSTOMER SERVICE PLATFORM REPORT\n",
      "============================================================\n",
      "\n",
      "👥 AGENT PERFORMANCE:\n",
      "\n",
      "  Alex:\n",
      "     • Service: Azure\n",
      "     • Model: None\n",
      "     • Tickets Handled: 0\n",
      "     • Total Cost: $0.000000\n",
      "     • Avg Cost/Ticket: $0.000000\n",
      "\n",
      "  Sarah:\n",
      "     • Service: Ollama\n",
      "     • Model: None\n",
      "     • Tickets Handled: 0\n",
      "     • Total Cost: $0.000000\n",
      "     • Avg Cost/Ticket: $0.000000\n",
      "\n",
      "  Mike:\n",
      "     • Service: Ollama\n",
      "     • Model: None\n",
      "     • Tickets Handled: 0\n",
      "     • Total Cost: $0.000000\n",
      "     • Avg Cost/Ticket: $0.000000\n",
      "\n",
      "  Emma:\n",
      "     • Service: Azure\n",
      "     • Model: None\n",
      "     • Tickets Handled: 0\n",
      "     • Total Cost: $0.000000\n",
      "     • Avg Cost/Ticket: $0.000000\n",
      "\n",
      "GRAND TOTAL COST: $0.000000\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "platform = CustomerServicePlatform(agent_team, router)\n",
    "print(platform.export_platform_report())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
